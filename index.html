<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A novel approach that leverages large vision-language models (VLMs) to automate the estimation, generation, and editing of 3D garment sewing patterns from images or text descriptions.">
  <meta name="keywords" content="Garment, Sewing Pattern, Fashion, LLM, VLM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ChatGarment: Garment Estimation, Generation and Editing via Large Language Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ChatGarment: Garment Estimation, Generation and Editing via Large Language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=2qsqnJEAAAAJ&hl=en">Siyuan Bian</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://chxu-001.github.io/">Chenghao Xu</a><sup>1,3</sup>,</span>
            <span class="author-block">
              <a href="https://xiuyuliang.cn/">Yuliang Xiu</a><sup>1,4</sup>,</span>
            <span class="author-block">
              <a href="https://dolorousrtur.github.io/">Artur Grigorev</a><sup>1,5</sup>,</span>
            <span class="author-block">
              <a href="https://itszhen.com/">Zhen Liu</a><sup>1,7</sup>,</span>
            <span class="author-block">
              <a href="https://www.mvig.org/">Cewu Lu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://ps.is.mpg.de/person/black">Michael J. Black</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=wNQQhSIAAAAJ&amp;hl=en&amp;oi=ao">Yao Feng</a><sup>1,5,6</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Max Planck Institute for Intelligent Systems, </span>
            <span class="author-block"><sup>2</sup>Shanghai Jiao Tong University, </span>
            <span class="author-block"><sup>3</sup>EPFL, </span>
            <span class="author-block"><sup>4</sup>Westlake University, </span>
            <span class="author-block"><sup>5</sup>ETH ZÃ¼rich, </span>
            <span class="author-block"><sup>6</sup>Meshcapade, </span>
            <span class="author-block"><sup>7</sup>Mila, University of Montreal</span>
        </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <p style="text-align: center;"><img src="./static/images/teaser_1209.png" alt="" style="max-width:83%;"></p>
      <h2 class="subtitle has-text-centered">
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce ChatGarment, a novel approach that leverages large vision-language models (VLMs) to automate the estimation, generation, and editing of 3D garment sewing patterns from images or text descriptions. 
          </p>
          <p>
            Unlike previous methods that often lack robustness and interactive editing capabilities, ChatGarment finetunes a VLM to produce GarmentCode, a JSON-based, language-friendly format for 2D sewing patterns, enabling both estimating and editing from images and text instructions. To optimize performance, we refine GarmentCode by expanding its support for more diverse garment types and simplifying its structure, making it more efficient for VLM finetuning. Additionally, we develop an automated data construction pipeline to generate a large-scale dataset of image-to-sewing-pattern and text-to-sewing-pattern pairs, empowering ChatGarment with strong generalization across various garment types.  
          </p>
          <p>
            Extensive evaluations demonstrate ChatGarment's ability to accurately reconstruct, generate, and edit garments from multimodal inputs, highlighting its potential to revolutionize workflows in fashion and gaming applications.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/-Fj4mN3jeNo?si=bsmBpTZ5Tk8UryZP&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>

        <div class="container is-max-desktop">
          <div class="hero-body">
            <p style="text-align: center;"><img src="./static/images/GarmentLLM-dialog2.png" alt="" style="max-width:100%;"></p>
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>We utilize the large vision-language model for sewing pattern understanding.</b> ChatGarment features three dialog modes. Users can utilize images as visual inputs for garment creation or guidance, while text instructions define specific tasks. These inputs are transformed into GarmentCode, which is then converted to 3D garments.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Image-based Reconstruction Results</h2>

        <div class="container is-max-desktop">
          <div class="hero-body">
            <p style="text-align: center;"><img src="./static/images/compare_img_recon.png" alt="" style="max-width:100%;"></p>
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>Results of image-based reconstruction.</b> Unlike SewFormer and DressCode, which often mess up or miss the garments, ChatGarment could faithfully capture the shape, style and the composition of the target garments.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Text-based Generation Results</h2>

        <div class="container is-max-desktop">
          <div class="hero-body">
            <p style="text-align: center;"><img src="./static/images/text_generation.png" alt="" style="max-width:100%;"></p>
            <h2 class="subtitle has-text-centered">
            </h2>
          </div>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>Results of garment generation from texts.</b> ChatGarment follows the instruction more accurately, generating more precise details (types, sleeves, length, etc.) compared to DressCode.
          </p>
        </div>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Garment Editing Results</h2>

        <div class="container is-max-desktop">
          <!-- <div class="hero-body">
            <p style="text-align: center;"><img src="./static/images/edit_comparison_new.png" alt="" style="max-width:100%;"></p>
            <h2 class="subtitle has-text-centered">
            </h2>
          </div> -->
          <video id="video_edit" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_edit.mp4"
                    type="video/mp4">
          </video>
          <video id="video_edit2" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_edit2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>Results of garment editing.</b> The models need to edit the source garment according to the given editing instructions in the prompt boxes. ChatGarment accurately modifies the targeted garment part according to the input prompt. In contrast, methods based on SewFormer or DressCode often fail to precisely follow the prompt instructions and alter other untouched areas of the garment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <h2 class="title is-3">Garment Editing Results</h2>
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_edit.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/video_edit2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            <b>Results of garment editing.</b> The models (SewFormer, DressCode, and our ChatGarment) are tasked with editing the source garment shown in the source image according to the given editing instructions in the prompt boxes. ChatGarment accurately modifies the targeted garment part according to the input prompt. In contrast, methods based on SewFormer or DressCode often fail to precisely follow the prompt instructions and alter other untouched areas of the garment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          The website template was borrowed from <a
          href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We would like to thank Keunhong Park for sharing the template.
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
